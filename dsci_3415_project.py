# -*- coding: utf-8 -*-
"""DSCI 3415 Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kToT64Vz68XBhQDYCZioKkuZ7_KBGUh8

**Predicting Premier League Match Winners Based On First-Half Events**

Fundamentals of Machine Learning (DSCI 3415) - Project Code

Omar Moustafa (900222400)

Nour Kahky (900221042)

May 22, 2025
"""

# @title Importing the Necessary Libraries

import os
import string
import random
import json
import zipfile
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from numpy.linalg import pinv
from collections import Counter, defaultdict
from sklearn.model_selection import LeaveOneOut, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# @title Loading the Necessary Datasets

teams = "/content/drive/MyDrive/teams.json"
teams = json.load(open(teams))

matches_England = "/content/drive/MyDrive/matches/matches_England.json"
matches_England = json.load(open(matches_England))

events_England = "/content/drive/MyDrive/events/events_England.json"
events_England = json.load(open(events_England))

# @title Building a DataFrame of the English Premier League

matches_df = pd.json_normalize(matches_England)
print("Available columns in matches_df:")
print(matches_df.columns)

summary_data = []

for match in matches_England:
    match_id = match.get('wyId')
    date = match.get('date')

    teams_data = match.get('teamsData', {})
    if len(teams_data) == 2:
        team_ids = list(teams_data.keys())
        team1 = teams_data[team_ids[0]]
        team2 = teams_data[team_ids[1]]

        team1_name = team1.get('name', 'Unknown')
        team2_name = team2.get('name', 'Unknown')
        team1_score = team1.get('score', None)
        team2_score = team2.get('score', None)

        summary_data.append({
            'match_id': match_id,
            'date': date,
            'team1_id': team_ids[0],
            'team1_name': team1_name,
            'team1_score': team1_score,
            'team2_id': team_ids[1],
            'team2_name': team2_name,
            'team2_score': team2_score,
        })

# Mapping dictionary from the team ID to the team name
team_id_to_name = {str(team['wyId']): team['name'] for team in teams}

matches_summary_df = pd.DataFrame(summary_data)

# Mapping team1 and team2 IDs to names using the dictionary
matches_summary_df['team1_name'] = matches_summary_df['team1_id'].map(team_id_to_name)
matches_summary_df['team2_name'] = matches_summary_df['team2_id'].map(team_id_to_name)

matches_summary_df.head(3)

# @title Building a DataFrame of First-Half Events

summary_data2 = []

for event in events_England:

    if event['matchPeriod'] != '1H':
      continue

    match_id = event.get('matchId')
    team_id = event.get('teamId')
    event_type = event.get('eventName')

    summary_data2.append({
        'match_id': match_id,
        'team_id': team_id,
        'event_type': event_type,
    })

events_summary_df = pd.DataFrame(summary_data2)

events_summary_df.head(3)

# Group by match and team, then count each event type
event_counts = events_summary_df.groupby(['match_id', 'team_id', 'event_type']).size().unstack(fill_value = 0).reset_index()

event_counts['team_name'] = event_counts['team_id'].astype(str).map(team_id_to_name)

event_counts.head(3)

# @title Merging the 2 DataFrames into 1

# Create Team 1 and Team 2 Stats
team1_stats = event_counts.copy()
team1_stats.columns = [f'team1_{col}' if col not in ['match_id', 'team_id'] else col for col in team1_stats.columns]

team2_stats = event_counts.copy()
team2_stats.columns = [f'team2_{col}' if col not in ['match_id', 'team_id'] else col for col in team2_stats.columns]

matches_summary_df['team1_id'] = matches_summary_df['team1_id'].astype(int)
matches_summary_df['team2_id'] = matches_summary_df['team2_id'].astype(int)

# Merge With Match Outcomes
merged_df1 = pd.merge(matches_summary_df, team1_stats, left_on = ['match_id', 'team1_id'], right_on = ['match_id', 'team_id'], how = 'left')
merged_df1 = merged_df1.drop(columns = ['team_id'])

merged_df = pd.merge(merged_df1, team2_stats, left_on = ['match_id', 'team2_id'], right_on = ['match_id', 'team_id'], how = 'left')

# Adding a 'winner' column which says who won the game between team1 and team2 or if it was a draw
merged_df = merged_df.dropna(subset = ['team1_score', 'team2_score'])

def get_winner(row):
    if row['team1_score'] > row['team2_score']:
        return 'team1'
    elif row['team1_score'] < row['team2_score']:
        return 'team2'
    else:
        return 'draw'

merged_df['winner'] = merged_df.apply(get_winner, axis = 1)
merged_df.head(3)

# @title Model Training #1 - Logistic Regression (LR)

# Select only valid feature columns again
feature_cols = [col for col in merged_df.columns
                if (col.startswith('team1_') or col.startswith('team2_'))
                and not col.endswith('_name')
                and col != 'team2_team_name']

X = merged_df[feature_cols].fillna(0)

# Map string labels to numbers
y = merged_df['winner'].map({'team1': 0, 'team2': 1, 'draw': 2})

valid_rows = ~y.isna()
X = X[valid_rows]
y = y[valid_rows]

X_scaled = StandardScaler().fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.2, random_state = 42)

print("Training y distribution:")
print(y_train.value_counts())

clf = LogisticRegression(max_iter = 1000)
clf.fit(X_train, y_train)

y_pred_lr = clf.predict(X_test)
print(classification_report(y_test, y_pred_lr, target_names = ['team1', 'team2', 'draw']))

print()

# Model Refinement & Interpretation
feature_importance = pd.Series(clf.coef_[0], index = X.columns).sort_values(ascending = False)
print("Top 10 Feature Importances:\n", feature_importance.head(10))

# Confusion Matrix 1 - Logistic Regression
cm = confusion_matrix(y_test, y_pred_lr)
disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['team1', 'team2', 'draw'])
disp.plot(cmap = plt.cm.Blues)
plt.show()

# @title Model Training #2 - Random Forest (RF) Classifier

rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)
rf_clf.fit(X_train, y_train)

y_pred_rf = rf_clf.predict(X_test)
print("Classification Report:\n", classification_report(y_test, y_pred_rf))

print()

importances = pd.Series(rf_clf.feature_importances_, index = X.columns).sort_values(ascending = False)
print("Top 10 Feature Importances:\n", importances.head(10))

# Confusion Matrix 2 - Random Forest
cm = confusion_matrix(y_test, y_pred_rf)
disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['team1', 'team2', 'draw'])
disp.plot(cmap = plt.cm.Blues)
plt.show()

# @title Model Training #3 - K-Nearest Neighbors (KNN)

knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(X_train, y_train)

y_pred_knn = knn.predict(X_test)
print("KNN Classification Report:\n", classification_report(y_test, y_pred_knn))

# Confusion Matrix 3 - KNN
cm = confusion_matrix(y_test, y_pred_knn)
disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['team1', 'team2', 'draw'])
disp.plot(cmap = plt.cm.Blues)
plt.show()

# @title Average Accuracy For Each Method After 10 Runs

# Repeat 80/20 proportion train-test split 10 times
accuracies = {'LogisticRegression': [], 'RandomForest': [], 'KNN': []}

team_prediction_tracker = defaultdict(lambda: {'correct': 0, 'total': 0})

for i in range(10):
    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(
        X_scaled, y, X.index, test_size = 0.2, random_state = 42 + i, stratify = y
    )

    # Logistic Regression (Model 1)
    clf_lr = LogisticRegression(max_iter = 1000)
    clf_lr.fit(X_train, y_train)
    y_pred_lr = clf_lr.predict(X_test)
    accuracies['LogisticRegression'].append(accuracy_score(y_test, y_pred_lr))

    # Random Forest (Model 2)
    clf_rf = RandomForestClassifier(n_estimators = 100, random_state = 42)
    clf_rf.fit(X_train, y_train)
    y_pred_rf = clf_rf.predict(X_test)
    accuracies['RandomForest'].append(accuracy_score(y_test, y_pred_rf))

    # KNN (Model 3)
    clf_knn = KNeighborsClassifier(n_neighbors = 5)
    clf_knn.fit(X_train, y_train)
    y_pred_knn = clf_knn.predict(X_test)
    accuracies['KNN'].append(accuracy_score(y_test, y_pred_knn))

    # Track per-team accuracy using Random Forest
    for idx, pred, actual in zip(idx_test, y_pred_rf, y_test):
        row = merged_df.loc[idx]
        actual_team = row['team1_name'] if actual == 0 else row['team2_name'] if actual == 1 else 'Draw'
        predicted_team = row['team1_name'] if pred == 0 else row['team2_name'] if pred == 1 else 'Draw'

        if actual_team == predicted_team:
            team_prediction_tracker[actual_team]['correct'] = team_prediction_tracker[actual_team]['correct'] + 1
        team_prediction_tracker[actual_team]['total'] = team_prediction_tracker[actual_team]['total'] + 1

# Each Model's Average Accuracy
print("Average Accuracies Over 10 Iterations/Runs:")
print()
for model_name, acc_list in accuracies.items():
    print(f"{model_name}: {np.mean(acc_list):.4f}")
    print()

# @title Which Teams Are Better Predicted Than Others?

# Compute Per-Team Accuracy
team_accuracies = {}
for team, stats in team_prediction_tracker.items():
    if team == "Draw":
        continue
    accuracy = stats['correct'] / stats['total'] if stats['total'] > 0 else 0
    team_accuracies[team] = accuracy

sorted_teams = sorted(team_accuracies.items(), key = lambda x: x[1], reverse = True)
teams, scores = zip(*sorted_teams)

plt.figure(figsize = (10, 6))
plt.barh(teams, scores, color = "skyblue", edgecolor = 'black')
plt.xlabel('Accuracy')
plt.ylabel('Team')
plt.title('Per-Team Accuracy')
plt.tight_layout()
plt.show()

# @title Some Real Examples/Predictions

# Store corresponding indices for original rows
X_train_indices, X_test_indices = train_test_split(X.index, test_size = 0.2, random_state = 42)

# Sample 3 indices from the test set
sample_indices = np.random.choice(X_test_indices, size = 3, replace = False)

for i in sample_indices:
    row = merged_df.loc[i]
    input_data = X.loc[i].values.reshape(1, -1)
    prediction = rf_clf.predict(input_data)[0]
    actual = y.loc[i]

    team1 = row['team1_name']
    team2 = row['team2_name']
    date = row['date']

    prediction_label = team1 if prediction == 0 else team2 if prediction == 1 else 'Draw'
    actual_label = team1 if actual == 0 else team2 if actual == 1 else 'Draw'

    print(f"Match: {team1} vs {team2} on {date}")
    print()
    print(f"Model Prediction: {prediction_label}")
    print(f"Actual Result: {actual_label}")
    print()
    print("First-Half Statistics of Important Features:")
    print(f"{team1} - Shots: {row['team1_Shot']}, Fouls: {row['team1_Foul']}, Passes: {row['team1_Pass']}")
    print(f"{team2} - Shots: {row['team2_Shot']}, Fouls: {row['team2_Foul']}, Passes: {row['team2_Pass']}")
    print("-" * 87)

